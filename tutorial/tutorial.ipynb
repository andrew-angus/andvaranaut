{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andvaranaut tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Module (Input distributions specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin Hypercube Sampling\n",
    "Import items form forward module as well as utils module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from andvaranaut.forward import *\n",
    "from andvaranaut.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Magic features for development purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User supplies target function, which takes a 1D numpy array of nx inputs and returns a 1D numpy array of ny outputs. They must also supply a list of univariate distributions from scipy stats for each of the nx inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example target function (2 inputs, 2 outputs)\n",
    "# A more complex target function will produce an input file, \n",
    "# execute external code, and perform post-processing on output\n",
    "def test_fun(x):\n",
    "  x1,x2 = x\n",
    "  return np.array([x1**2+x2,x1**3*x2**2])\n",
    "\n",
    "# Input variable probability distributions\n",
    "import scipy.stats as st\n",
    "sample_space = [st.uniform(loc=0,scale=2),\\\n",
    "                st.norm(loc=1,scale=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Latin hypercube class instance, with correct arguments\n",
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun,\\\n",
    "       parallel=False,nproc=1) # Last 2 args are optional & default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling makes use of the latin_random function from py-design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sample input distributions by LHC and evaluate target function\n",
    "l.sample(nsamps=4)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel execution makes use of the ray package. This also works with SLURM submission if a SLURM script calls a python script with these commands in. (Tutorial will be added at a later date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Can also execute target function evaluation in parallel\n",
    "l.parallel = True\n",
    "l.nproc = 4\n",
    "l.sample(nsamps=4)\n",
    "ray.shutdown() # Shutdown ray parallelism, this command only good for interactive sessions\n",
    "l.parallel = False\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot output distributions based on kernel density estimation\n",
    "l.y_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optionally delete n samples\n",
    "# Default is deletion by closest sample to a coarse LHC of number of samples for deletion\n",
    "l.del_samples(ndels=2,method='coarse_lhc')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# Can also delete by random indexing\n",
    "l.del_samples(ndels=2,method='random')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# or by specific data indexes\n",
    "l.del_samples(method='specific',idx=[0,1])\n",
    "print(l.x)\n",
    "print(l.y,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If datasets exist then it is possible to set the class attributes directly with these. They must be in the form of 2d numpy float arrays. An additional consideration is the provided x data must be compatible with the existing distributions. WARNING: This will likely invalidate relationship of samples to selected input distributions and therefore invalidate output distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(5,2)\n",
    "y = np.random.rand(5,2)\n",
    "l.set_data(x=x,y=y)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian process surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the arguments provided to the lhc class, there are additional arguments for a list of classes which handle conversion and reversion of the x and y datasets, respectively. These are necessary for optimising surrogate performance, and usually consist of transforming bounded ranges on inputs and outputs to unbounded. Normalisations to get numbers O(1) are also useful and can be implemented either here or within the target function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These conversion/reversion arguments are optional, and can be left blank if desired. Standard methods are provided in andvaranaut.utils, with the logarithm and uniform classes shown below for clarity on the format. A user can define their own class in this format, as long as any additional arguments like the distribution object in uniform are packaged into partial functions within the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK NEXT BOX STILL UP TO DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert positive values to unbounded with logarithm\n",
    "def log_con(y):\n",
    "  return np.log10(y)\n",
    "# Revert logarithm with power\n",
    "def log_rev(y):\n",
    "  return np.power(10,y)\n",
    "class logarithm:\n",
    "  def __init__(self):\n",
    "    self.con = log_con # Conversion function\n",
    "    self.rev = log_rev # Reversion function\n",
    "\n",
    "from functools import partial\n",
    "# Convert uniform dist samples into standard uniform \n",
    "def std_uniform(x,dist):\n",
    "  intv = dist.interval(1.0)\n",
    "  x = (x-intv[0])/(intv[1]-intv[0])\n",
    "  return x\n",
    "# Revert to original uniform distributions\n",
    "def uniform_rev(x,dist):\n",
    "  intv = dist.interval(1.0)\n",
    "  x = x*(intv[1]-intv[0])+intv[0]\n",
    "  return x\n",
    "class uniform:\n",
    "  def __init__(self,dist):\n",
    "    self.con = partial(std_uniform,dist=dist)\n",
    "    self.rev = partial(uniform_rev,dist=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define lists of conversion/reversion class instances for each x and y variable\n",
    "xconrevs = [uniform(sample_space[0]),normal(sample_space[1])]\n",
    "yconrevs = [None,logarithm()]\n",
    "# Instance of gp, only nx, ny, dists, and target are req\n",
    "g = GP(kernel='RBF',noise=False,xconrevs=xconrevs,yconrevs=yconrevs,\\\n",
    "       nx=2,ny=2,priors=sample_space,target=test_fun,parallel=False,nproc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods from lhc class are inherited by the GP class with some additions like automatic conversion of new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.sample(2)\n",
    "print(g.x)\n",
    "print(g.y)\n",
    "print(g.xc)\n",
    "print(g.yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can change conversion/reversion classes without reinitialising class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xconrevs = [logit_logistic(sample_space[0]),None]\n",
    "yconrevs = [None,nonneg()]\n",
    "g.change_conrevs(xconrevs,yconrevs)\n",
    "print(g.x)\n",
    "print(g.y)\n",
    "print(g.xc)\n",
    "print(g.yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some more samples and fit GP surrogate to converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.sample(nsamps=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.fit(restarts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your fitted model will be a GPy GPRegression object and as such will retain all GPy functionality. It can be accessed as the 'm' attribute of the gp class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(g.m[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train-test set and produce plots to assess GP performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.train_test(training_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.test_plots(revert=True,restarts=1,yplots=True,xplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can change model details (kernel choice and whether data contains noise) without reinitialsing class. This will scrub any fitted model and require a new call to gp.fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.change_model(kernel='Exponential',noise=True)\n",
    "g.fit()\n",
    "g.test_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagate uncertainty using surrogate and get target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.change_model(kernel='Exponential',noise=False)\n",
    "g.fit()\n",
    "x,y = g.y_dist(mode='hist_kde',nsamps=10000,return_data=True,surrogate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot also the distrutions based on underyling 100 LHC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.y_dist(surrogate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 1000 actual function evaluations for comparison with GP surrogate plots. GP based on 100 evaluations gives good qualitative agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.y_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lengthscales of the fitted GP give an insight into sensitivities of the outputs to the inputs. Relative log importances can be plotted either using converted or original datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.relative_importances()\n",
    "g.relative_importances(original_data=True,restarts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to LHC samples, there is also the option of utilising adaptive sampling. This aims to add samples at points which best balance improved accuracy and input parameter space exploration. Method based on Mohammadi, Hossein, et al. \"Cross-validation based adaptive sampling for Gaussian process models.\" arXiv preprint arXiv:2005.01814 (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GP(kernel='RBF',noise=False,xconrevs=xconrevs,yconrevs=yconrevs,\\\n",
    "       nx=2,ny=2,priors=sample_space,target=test_fun,parallel=False,nproc=4)\n",
    "g.sample(50)\n",
    "g.sample(nsamps=5,batchsize=2,method='adaptive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andvaranaut.inverse import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a posteriori (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MAP(nx_exp=1,nx_model=1,ny=2,priors=sample_space[1:],\\\n",
    "        target=test_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.random.rand(1,2)\n",
    "print(xtest)\n",
    "y = np.array([test_fun(xtest[0])])\n",
    "m.set_observations(y=y,y_noise=None,\\\n",
    "                   x_exp=xtest[:,0].reshape((1,1)))\n",
    "print(m.y_obv)\n",
    "print(m.y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.opt()\n",
    "print(m.xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP using a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GPMAP(kernel='Matern32',noise=False,nx_exp=1,nx_model=1,ny=2,priors=sample_space,\\\n",
    "        target=test_fun,xconrevs=[uniform(sample_space[0]),normal(sample_space[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.sample(10,batchsize=1,method='adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.m[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.random.rand(1,2)\n",
    "print(xtest)\n",
    "y = np.array([test_fun(xtest[0])])\n",
    "gm.set_observations(y=y,y_noise=None,\n",
    "                   x_exp=xtest[:,0].reshape((1,1)))\n",
    "print(gm.y_obv)\n",
    "print(gm.y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.opt()\n",
    "print(gm.xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lhc class including datasets\n",
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun)\n",
    "l.sample(2)\n",
    "save_object(obj=l,fname='lhc_tut.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load lhc class\n",
    "l = load_object(fname='lhc_tut.pickle')\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard conversion/reversion classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples were shown previously in the tutorial but the full list will be given here for completeness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal - requires dist argument upon initialisation and converts samples from any normal distribution to a standard normal sample. \n",
    "  \n",
    "uniform - as above but any uniform distribution to standard uniform.  \n",
    "  \n",
    "logit-logistic - requires dist argument and converts any uniform distribution sample to an unbounded range via logit  \n",
    "  \n",
    "probit - as above but converts to standard normal sample via distribution cdf's  \n",
    "  \n",
    "nonneg - converts any non-negative values to unbounded values by the transformation y' = y/(1+y) which has a range [0,1] and then taking the logit.  \n",
    "  \n",
    "logarithm - takes a log with base ten to transform any positive values to unbounded  \n",
    "\n",
    "normalise - requires a fac argument and applies a y/fac conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
