{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andvaranaut tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all modules from andvaranaut package\n",
    "from andvaranaut import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Magic features for development purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LHC Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User supplies target function, which takes a 1D numpy array of nx inputs and returns a 1D numpy array of ny outputs. They must also supply a list of univariate distributions from scipy stats for each of the nx inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example target function (2 inputs, 2 outputs)\n",
    "# A more complex target function will produce an input file, \n",
    "# execute external code, and perform post-processing on output\n",
    "def test_fun(x):\n",
    "  x1,x2 = x\n",
    "  return np.array([x1**2+x2,x1**3*x2**2])\n",
    "\n",
    "# Input variable probability distributions\n",
    "import scipy.stats as st\n",
    "sample_space = [st.uniform(loc=0,scale=2),\\\n",
    "                st.norm(loc=1,scale=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Latin hypercube class instance, with correct arguments\n",
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun,\\\n",
    "       parallel=False,nproc=1,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling makes use of the latin_random function from py-design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample input distributions by LHC and evaluate target function\n",
    "l.sample(nsamps=4)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel execution makes use of the ray package. This also works with SLURM submission if a SLURM script calls a python script with these commands in. (Tutorial will be added at a later date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can also execute target function evaluation in parallel\n",
    "l.parallel = True\n",
    "l.nproc = 4\n",
    "l.sample(nsamps=4)\n",
    "ray.shutdown() # Shutdown ray parallelism, this command only good for interactive sessions\n",
    "l.parallel = False\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot output distributions based on kernel density estimation\n",
    "l.y_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optionally delete n samples\n",
    "# Default is deletion by closest sample to a coarse LHC of number of samples for deletion\n",
    "l.del_samples(ndels=2,method='coarse_lhc')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# Can also delete by random indexing\n",
    "l.del_samples(ndels=2,method='random')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# or by specific data indexes\n",
    "l.del_samples(method='specific',idx=[0,1])\n",
    "print(l.x)\n",
    "print(l.y,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If datasets exist then it is possible to set the class attributes directly with these. They must be in the form of 2d numpy float arrays. An additional consideration is the provided x data must be compatible with the existing distributions. WARNING: This will likely invalidate relationship of samples to selected input distributions and therefore invalidate output distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(5,2)\n",
    "y = np.random.rand(5,2)\n",
    "l.set_data(x=x,y=y)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the arguments provided to the lhc class, there are additional arguments for a list of classes which handle conversion and reversion of the x and y datasets, respectively. These are necessary for optimising surrogate performance, and usually consist of transforming bounded ranges on inputs and outputs to unbounded. Normalisations to get numbers O(1) are also useful and can be implemented either here or within the target function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These conversion/reversion arguments are optional, and can be left blank if desired. Standard methods are provided in andvaranaut.transform. A user can define their own conversion classes in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define lists of conversion/reversion class instances for each x and y variable\n",
    "xconrevs = [uniform(sample_space[0]),normal(sample_space[1])]\n",
    "yconrevs = [None,logarithm()]\n",
    "# Instance of gp, only nx, ny, dists, and target are req\n",
    "g = GP(kernel='RBF',noise=False,xconrevs=xconrevs,yconrevs=yconrevs,\\\n",
    "       nx=2,ny=2,priors=sample_space,target=test_fun,parallel=False,nproc=4,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods from lhc class are inherited by the GP class with some additions like automatic conversion of new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.sample(2)\n",
    "print(g.x)\n",
    "print(g.y)\n",
    "print(g.xc)\n",
    "print(g.yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can change conversion/reversion classes without reinitialising class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xconrevs = [logit_logistic(sample_space[0]),None]\n",
    "yconrevs = [None,nonneg()]\n",
    "g.change_conrevs(xconrevs,yconrevs)\n",
    "print(g.x)\n",
    "print(g.y)\n",
    "print(g.xc)\n",
    "print(g.yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some more samples and fit GP surrogate to converted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.sample(nsamps=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.fit(restarts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your fitted model will be a GPy GPRegression object and as such will retain all GPy functionality. It can be accessed as the 'm' attribute of the gp class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.m[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a train-test set and produce plots to assess GP performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.train_test(training_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.test_plots(revert=True,restarts=1,yplots=True,xplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can change model details (kernel choice and whether data contains noise) without reinitialsing class. This will scrub any fitted model and require a new call to gp.fit()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.change_model(kernel='Exponential',noise=True,normalise=True)\n",
    "g.test_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propagate uncertainty using surrogate and get target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.fit()\n",
    "x,y = g.y_dist(mode='hist_kde',nsamps=1000,return_data=True,surrogate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot also the distrutions based on underyling 100 LHC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.y_dist(surrogate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 1000 actual function evaluations for comparison with GP surrogate plots. GP based on 100 evaluations gives good qualitative agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l.y_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lengthscales of the fitted GP give an insight into sensitivities of the outputs to the inputs. Relative log importances can be plotted either using converted or original datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g.relative_importances()\n",
    "g.relative_importances(original_data=True,restarts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to LHC samples, there is also the option of utilising adaptive sampling. This aims to add samples at points which best balance improved accuracy and input parameter space exploration. Method based on Mohammadi, Hossein, et al. \"Cross-validation based adaptive sampling for Gaussian process models.\" arXiv preprint arXiv:2005.01814 (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GP(kernel='RBF',noise=False,xconrevs=xconrevs,yconrevs=yconrevs,\\\n",
    "       nx=2,ny=2,priors=sample_space,target=test_fun,parallel=False,nproc=4,verbose=True)\n",
    "g.sample(50)\n",
    "g.sample(nsamps=5,batchsize=2,method='adaptive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a posteriori (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MAP(nx_exp=1,nx_model=1,ny=2,priors=sample_space[1:],\\\n",
    "        target=test_fun,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.random.rand(1,2)\n",
    "print(xtest)\n",
    "y = np.array([test_fun(xtest[0])])\n",
    "m.set_observations(y=y,y_noise=None,\\\n",
    "                   x_exp=xtest[:,0].reshape((1,1)))\n",
    "print(m.y_obv)\n",
    "print(m.y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.opt()\n",
    "print(m.xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP using a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GPMAP(kernel='Matern32',noise=True,nx_exp=1,nx_model=1,ny=2,priors=sample_space,\\\n",
    "        target=test_fun,xconrevs=[uniform(sample_space[0]),normal(sample_space[1])],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gm.m[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtest = np.random.rand(1,2)\n",
    "print(xtest)\n",
    "y = np.array([test_fun(xtest[0])])\n",
    "gm.set_observations(y=y,\n",
    "                   x_exp=xtest[:,0].reshape((1,1)))\n",
    "print(gm.y_obv)\n",
    "print(gm.y_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gm.opt()\n",
    "print(gm.xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save lhc class including datasets\n",
    "l = LHC(nx=2,ny=2,priors=sample_space,target=test_fun)\n",
    "l.sample(2)\n",
    "save_object(obj=l,fname='lhc_tut.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load lhc class\n",
    "l = load_object(fname='lhc_tut.pickle')\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T15:38:10.108040Z",
     "iopub.status.busy": "2023-05-18T15:38:10.107667Z",
     "iopub.status.idle": "2023-05-18T15:38:10.112737Z",
     "shell.execute_reply": "2023-05-18T15:38:10.112052Z",
     "shell.execute_reply.started": "2023-05-18T15:38:10.107940Z"
    }
   },
   "source": [
    "## GPMCMC Module - To be updated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
