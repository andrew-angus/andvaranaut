{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andvaranaut tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Module (Input distributions specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latin Hypercube Sampling\n",
    "Import items form forward module as well as utils module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andvaranaut.forward import *\n",
    "from andvaranaut.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic features for development purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User supplies target function, which takes a 1D numpy array of nx inputs and returns a 1D numpy array of ny outputs. They must also supply a list of univariate distributions from scipy stats for each of the nx inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example target function (2 inputs, 2 outputs)\n",
    "# A more complex target function will produce an input file, \n",
    "# execute external code, and perform post-processing on output\n",
    "def test_fun(x):\n",
    "  x1,x2 = x\n",
    "  return np.array([x1+x2,10000*x1**2*x2**2])\n",
    "\n",
    "# Input variable probability distributions\n",
    "import scipy.stats as st\n",
    "sample_space = [st.uniform(loc=0,scale=2),\\\n",
    "                st.norm(loc=1,scale=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latin hypercube class instance, with correct arguments\n",
    "l = lhc(nx=2,ny=2,dists=sample_space,target=test_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling makes use of the latin_random function from py-design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input distributions by LHC and evaluate target function\n",
    "l.sample(nsamps=4)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel execution makes use of the ray package. This also works with SLURM submission if a SLURM script calls a python script with these commands in. (Tutorial will be added at a later date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also execute target function evaluation in parallel\n",
    "l.sample(nsamps=4,parallel=True,nproc=4)\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting output distributions makes use of the kdeplot function from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot output distributions based on kernel density estimation\n",
    "l.y_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally delete n samples\n",
    "# Default is deletion by closest sample to a coarse LHC of number of samples for deletion\n",
    "l.del_samples(ndels=2,method='coarse_lhc')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# Can also delete by random indexing\n",
    "l.del_samples(ndels=2,method='random')\n",
    "print(l.x)\n",
    "print(l.y,'\\n')\n",
    "# or by specific data indexes\n",
    "l.del_samples(method='specific',idx=[0,1])\n",
    "print(l.x)\n",
    "print(l.y,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian process surrogate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the arguments provided to the lhc class, there are additional arguments for a list of classes which handle conversion and reversion of the x and y datasets, respectively. These are necessary for optimising surrogate performance, and usually consist of transforming bounded ranges on inputs and outputs to unbounded. Normalisations to get numbers O(1) are also useful and can be implemented either here or within the target function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These conversion/reversion arguments are optional, and can be left blank if desired. Standard methods are provided in andvaranaut.utils, with the logarithm and uniform classes shown below for clarity on the format. A user can define their own class in this format, as long as any additional arguments like the distribution function in uniform are packaged into partial functions within the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert positive values to unbounded with logarithm\n",
    "def log_con(y):\n",
    "  return np.log10(y)\n",
    "# Revert logarithm with power\n",
    "def log_rev(y):\n",
    "  return np.power(10,y)\n",
    "class logarithm:\n",
    "  def __init__(self):\n",
    "    self.con = log_con # Conversion function\n",
    "    self.rev = log_rev # Reversion function\n",
    "\n",
    "from functools import partial\n",
    "# Convert uniform dist samples into standard uniform \n",
    "def std_uniform(x,dist):\n",
    "  intv = dist.interval(1.0)\n",
    "  x = (x-intv[0])/(intv[1]-intv[0])\n",
    "  return x\n",
    "# Revert to original uniform distributions\n",
    "def uniform_rev(x,dist):\n",
    "  intv = dist.interval(1.0)\n",
    "  x = x*(intv[1]-intv[0])+intv[0]\n",
    "  return x\n",
    "class uniform:\n",
    "  def __init__(self,dist):\n",
    "    self.con = partial(std_uniform,dist=dist)\n",
    "    self.rev = partial(uniform_rev,dist=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of conversion/reversion classes for each x and y variable\n",
    "xconrevs = [logit_logistic(sample_space[0]),normal(sample_space[1])]\n",
    "yconrevs = [None,nonneg()]\n",
    "# Instance of gp\n",
    "g = gp(nx=2,ny=2,dists=sample_space,target=test_fun,xconrevs=xconrevs,yconrevs=yconrevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.sample(5)\n",
    "print(g.x)\n",
    "print(g.y)\n",
    "print(g.xc)\n",
    "print(g.yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lhc class including datasets\n",
    "save_object(obj=l,fname='lhc_tut.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lhc class\n",
    "l = load_object(fname='lhc_tut.pickle')\n",
    "print(l.x)\n",
    "print(l.y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
